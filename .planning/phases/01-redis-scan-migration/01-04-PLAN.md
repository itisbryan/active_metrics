---
phase: 01-redis-scan-migration
plan: 04
type: execute
wave: 3
depends_on: ["01-01", "01-02", "01-03"]
files_modified:
  - test/benchmark/redis_scan_benchmark.rb
autonomous: true

must_haves:
  truths:
    - "Benchmark script compares KEYS vs SCAN performance across dataset sizes"
    - "Tests small (100s), medium (1,000s), large (10,000s) datasets per research"
    - "Measures both performance and non-blocking behavior"
    - "Script can be run standalone with ruby command"
    - "Results indicate SCAN is non-blocking and within acceptable performance"
  artifacts:
    - path: "test/benchmark/redis_scan_benchmark.rb"
      provides: "Performance benchmark script for SCAN vs KEYS"
      min_lines: 80
      contains: "Benchmark.bm"
      contains: "create_test_dataset"
  key_links:
    - from: "test/benchmark/redis_scan_benchmark.rb"
      to: "redis-rb"
      via: "require 'redis'"
      pattern: "require.*redis"
    - from: "test/benchmark/redis_scan_benchmark.rb"
      to: "benchmark-ips"
      via: "require 'benchmark/ips'"
      pattern: "require.*benchmark"
---

<objective>
Create a performance benchmark script to validate SCAN implementation achieves performance parity with KEYS while remaining non-blocking. This script tests across three dataset sizes (small, medium, large) as specified in research, measuring both execution time and blocking behavior to ensure SCAN meets production requirements.

Purpose: Quantitatively validate SCAN is production-ready by measuring performance compared to KEYS and verifying non-blocking behavior across realistic dataset sizes.

Output: Standalone benchmark script (redis_scan_benchmark.rb) that can be run on-demand to compare KEYS vs SCAN performance.
</objective>

<execution_context>
@/Users/itisbryan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/itisbryan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-redis-scan-migration/01-redis-scan-migration-CONTEXT.md
@.planning/phases/01-redis-scan-migration/01-redis-scan-migration-RESEARCH.md
@lib/rails_performance/utils.rb
@lib/rails_performance/data_source.rb
@.planning/phases/01-redis-scan-migration/01-01-SUMMARY.md
@.planning/phases/01-redis-scan-migration/01-02-SUMMARY.md
@.planning/phases/01-redis-scan-migration/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Create performance benchmark script</name>
  <files>test/benchmark/redis_scan_benchmark.rb</files>
  <action>
    Create test/benchmark/redis_scan_benchmark.rb following research template:

    1. Create benchmark script with dataset size testing:
       ```ruby
       # frozen_string_literal: true

       require 'redis'
       require 'benchmark/ips'
       require_relative '../../lib/rails_performance/utils'
       require_relative '../../lib/rails_performance'

       class RedisScanBenchmark
         def initialize
           @redis = Redis.new
           @test_key_prefix = "performance|benchmark|#{Time.now.to_i}|"
         end

         def cleanup
           @redis.keys("#{@test_key_prefix}*").each { |k| @redis.del(k) }
         end

         def create_test_dataset(size)
           puts "\nCreating test dataset: #{size} keys..."
           size.times do |i|
             key = "#{@test_key_prefix}#{i}|datetime|20260204T#{i.to_s.rjust(4, '0')}|END|1.0.0"
             @redis.set(key, "{\"value\": #{i}}")
           end
           puts "Created #{size} keys"
         end

         def benchmark_keys_vs_scan(size, query)
           create_test_dataset(size)

           puts "\n" + "="*60
           puts "Benchmarking #{size} keys"
           puts "="*60

           Benchmark.bm(20) do |x|
             x.report("KEYS (#{size}):") do
               @redis.keys(query)
             end

             RailsPerformance.use_scan = true
             RailsPerformance.scan_count = 100

             x.report("SCAN count=10 (#{size}):") do
               @redis.scan_each(match: query, count: 10).to_a.sort
             end

             x.report("SCAN count=100 (#{size}):") do
               @redis.scan_each(match: query, count: 100).to_a.sort
             end

             x.report("SCAN count=1000 (#{size}):") do
               @redis.scan_each(match: query, count: 1000).to_a.sort
             end
           end

           cleanup
         end

         def run
           query = "#{@test_key_prefix}*"

           puts "\n"
           puts "="*60
           puts "Redis SCAN vs KEYS Benchmark"
           puts "="*60
           puts "Query pattern: #{query.gsub(@test_key_prefix, 'performance|benchmark|*')}"
           puts "="*60

           # Small dataset (100s)
           benchmark_keys_vs_scan(100, query)

           # Medium dataset (1,000s)
           benchmark_keys_vs_scan(1_000, query)

           # Large dataset (10,000s)
           benchmark_keys_vs_scan(10_000, query)

           puts "\n" + "="*60
           puts "Benchmark complete!"
           puts "="*60
           puts "\nKey findings:"
           puts "- SCAN should be within 2x of KEYS performance"
           puts "- SCAN must NOT block other Redis operations"
           puts "- COUNT=100 typically provides best balance"
           puts "- Higher COUNT values may increase individual call time"
         end
       end

       if __FILE__ == $0
         benchmark = RedisScanBenchmark.new
         benchmark.run
       end
       ```

    Per research requirements:
    - Test small (100s), medium (1,000s), large (10,000s) datasets
    - Measure KEYS vs SCAN with different COUNT values
    - Use Benchmark.bm for timing comparison
    - Provide clear output format showing times
    - Include guidance on interpreting results

    Per user decision: Success metric is both non-blocking AND performance parity vs KEYS.
  </action>
  <verify>Run ruby -c test/benchmark/redis_scan_benchmark.rb to check syntax</verify>
  <done>Benchmark script exists, syntax check passes, script tests 100/1,000/10,000 key datasets</done>
</task>

<task type="auto">
  <name>Run benchmark and document results</name>
  <files>test/benchmark/redis_scan_benchmark.rb</files>
  <action>
    Execute benchmark script and capture results:

    1. Run the benchmark:
       ```bash
       ruby test/benchmark/redis_scan_benchmark.rb
       ```

    2. Document results in a comment at the top of the file:
       ```ruby
       # frozen_string_literal: true

       # Benchmark Results: [DATE]
       #
       # Dataset | KEYS    | SCAN(10) | SCAN(100) | SCAN(1000) | Winner
       # --------|---------|----------|-----------|------------|--------
       # 100     | X.XXs   | Y.YYs    | Z.ZZs     | A.AAs      | SCAN(100)
       # 1,000   | X.XXs   | Y.YYs    | Z.ZZs     | A.AAs      | SCAN(1000)
       # 10,000  | X.XXs   | Y.YYs    | Z.ZZs     | A.AAs      | SCAN(1000)
       #
       # Key findings:
       # - SCAN is non-blocking (confirmed via separate Redis monitoring)
       # - SCAN performance is within 2x of KEYS across all dataset sizes
       # - COUNT=1000 provides best performance for larger datasets
       # - SCAN(100) provides good balance for most use cases
       #
       # Note: Actual KEYS times may vary based on Redis server configuration
       # and total database size. SCAN times remain consistent regardless of
       # total database size due to incremental iteration.
       #
       require 'redis'
       ...
       ```

    3. If benchmark cannot run (no Redis available), add placeholder comment:
       ```ruby
       # Benchmark Results: PENDING (requires Redis instance)
       # To run: ruby test/benchmark/redis_scan_benchmark.rb
       ```

    Per research: Critical test is verifying SCAN doesn't block other Redis operations.
    This is confirmed if SCAN completes without timeout and allows concurrent operations.
  </action>
  <verify>Run the benchmark and verify it completes without errors, results show SCAN is non-blocking and within acceptable performance</verify>
  <done>Benchmark runs successfully, results documented in file header, SCAN performance is acceptable</done>
</task>

</tasks>

<verification>
Overall phase checks:
1. test/benchmark/redis_scan_benchmark.rb file exists
2. Script requires redis and benchmark/ips gems
3. Script tests 3 dataset sizes: 100, 1,000, 10,000 keys
4. Script compares KEYS vs SCAN with different COUNT values
5. Script uses Benchmark.bm for timing
6. Script includes cleanup of test keys
7. Script is standalone (can run with ruby command)
8. Results are documented in file header comment
9. Results indicate SCAN is non-blocking
10. Results indicate SCAN is within 2x of KEYS performance
</verification>

<success_criteria>
1. Benchmark script created at test/benchmark/redis_scan_benchmark.rb
2. Script creates and cleans up test datasets
3. Tests 100, 1,000, and 10,000 key datasets
4. Compares KEYS vs SCAN with COUNT=10, 100, 1000
5. Uses Benchmark.bm for accurate timing
6. Clears test keys after each benchmark run
7. Script runs standalone (ruby test/benchmark/redis_scan_benchmark.rb)
8. Results documented in file header
9. SCAN is confirmed non-blocking (no timeouts, allows concurrent ops)
10. SCAN performance is within 2x of KEYS
11. Syntax check passes
</success_criteria>

<output>
After completion, create `.planning/phases/01-redis-scan-migration/01-04-SUMMARY.md` with:
- Benchmark results summary table
- Key findings from performance testing
- Recommended COUNT values for different scenarios
- Confirmation of non-blocking behavior
- Files created
- Any performance issues discovered
</output>
